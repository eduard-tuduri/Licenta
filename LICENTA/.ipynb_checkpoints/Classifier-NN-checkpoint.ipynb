{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LeakyReLU, Dropout, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # csv I/O\n",
    "\n",
    "IMG_SIZE = 299\n",
    "MODEL_NAME = 'xception'\n",
    "\n",
    "DATA_DIR= r'D:\\LICENTA\\processed_data\\size_{size1}x{size2}'.format(size1=IMG_SIZE, size2=IMG_SIZE)\n",
    "FEATURES_PATH = DATA_DIR +  r'\\train_biz_{name}_features.csv'.format(name=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_photos = pd.read_csv('train_photo_to_biz_ids.csv')\n",
    "train_photo_to_biz = pd.read_csv('train_photo_to_biz_ids.csv', index_col='photo_id')\n",
    "\n",
    "train_df = pd.read_csv(FEATURES_PATH)\n",
    "\n",
    "X = train_df['feature_vector'].values\n",
    "Y = train_df['label'].values\n",
    "\n",
    "def convert_label_to_array(str_label):\n",
    "    str_label = str_label[1:-1]\n",
    "    str_label = str_label.split(',')\n",
    "    return [int(x) for x in str_label if len(x) > 0]\n",
    "\n",
    "def convert_feature_to_vector(str_feature):\n",
    "    str_feature = str_feature[1:-1]\n",
    "    str_feature = str_feature.split(',')\n",
    "    return [float(x) for x in str_feature]\n",
    "\n",
    "Y = np.array([convert_label_to_array(y) for y in train_df['label']])\n",
    "X = np.array([convert_feature_to_vector(x) for x in train_df['feature_vector']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (1996, 2048)\n",
      "y_train:  (1996,)\n",
      "train_df:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business</th>\n",
       "      <th>label</th>\n",
       "      <th>feature_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 2, 3, 4, 5, 6, 7)</td>\n",
       "      <td>[0.12353174, 0.056759115, 0.10699466, 0.045236...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>(0, 1, 6, 8)</td>\n",
       "      <td>[0.19606702, 0.030776627, 0.032012787, 0.21252...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>(1, 2, 4, 5, 6, 7)</td>\n",
       "      <td>[0.13964602, 0.059296891, 0.10956762, 0.041540...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1006</td>\n",
       "      <td>(1, 2, 4, 5, 6)</td>\n",
       "      <td>[0.16115737, 0.023083402, 0.10019045, 0.051235...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1010</td>\n",
       "      <td>(0, 6, 8)</td>\n",
       "      <td>[0.12933584, 0.086438626, 0.062900275, 0.05014...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   business                  label  \\\n",
       "0      1000  (1, 2, 3, 4, 5, 6, 7)   \n",
       "1      1001           (0, 1, 6, 8)   \n",
       "2       100     (1, 2, 4, 5, 6, 7)   \n",
       "3      1006        (1, 2, 4, 5, 6)   \n",
       "4      1010              (0, 6, 8)   \n",
       "\n",
       "                                      feature_vector  \n",
       "0  [0.12353174, 0.056759115, 0.10699466, 0.045236...  \n",
       "1  [0.19606702, 0.030776627, 0.032012787, 0.21252...  \n",
       "2  [0.13964602, 0.059296891, 0.10956762, 0.041540...  \n",
       "3  [0.16115737, 0.023083402, 0.10019045, 0.051235...  \n",
       "4  [0.12933584, 0.086438626, 0.062900275, 0.05014...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"X_train: \", X.shape)\n",
    "print(\"y_train: \", Y.shape)\n",
    "print(\"train_df:\")\n",
    "train_df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y = mlb.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(2500, input_shape=(X.shape[1],)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1024))\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(365))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(9))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy', f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 3s - loss: 1.0883 - acc: 0.5051 - f1: 0.5108\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6477 - acc: 0.7388 - f1: 0.7292\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.5483 - acc: 0.7834 - f1: 0.7728\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.5070 - acc: 0.7977 - f1: 0.7872\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.4767 - acc: 0.8040 - f1: 0.7953\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.4454 - acc: 0.8104 - f1: 0.8017\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.4154 - acc: 0.8172 - f1: 0.8082\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.4156 - acc: 0.8137 - f1: 0.8063\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.4026 - acc: 0.8190 - f1: 0.8115\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.3934 - acc: 0.8289 - f1: 0.8245\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.3917 - acc: 0.8270 - f1: 0.8221\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.3835 - acc: 0.8291 - f1: 0.8219\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.3780 - acc: 0.8329 - f1: 0.8254\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.3757 - acc: 0.8341 - f1: 0.8256\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.3633 - acc: 0.8392 - f1: 0.8305\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.3623 - acc: 0.8427 - f1: 0.8360\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.3540 - acc: 0.8446 - f1: 0.8391\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.3518 - acc: 0.8460 - f1: 0.8412\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.3458 - acc: 0.8464 - f1: 0.8411\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.3429 - acc: 0.8476 - f1: 0.8409\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.3391 - acc: 0.8519 - f1: 0.8453\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.3347 - acc: 0.8531 - f1: 0.8464\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.3284 - acc: 0.8598 - f1: 0.8538\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.3242 - acc: 0.8606 - f1: 0.8548\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.3288 - acc: 0.8580 - f1: 0.8526\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.3187 - acc: 0.8599 - f1: 0.8536\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.3160 - acc: 0.8626 - f1: 0.8568\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.3124 - acc: 0.8621 - f1: 0.8567\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.3046 - acc: 0.8682 - f1: 0.8632\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.3067 - acc: 0.8662 - f1: 0.8604\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.3036 - acc: 0.8692 - f1: 0.8638\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.2977 - acc: 0.8695 - f1: 0.8643\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.2939 - acc: 0.8736 - f1: 0.8685\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.2929 - acc: 0.8721 - f1: 0.8669\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.2846 - acc: 0.8755 - f1: 0.8702\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.2867 - acc: 0.8753 - f1: 0.8698\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.2807 - acc: 0.8798 - f1: 0.8750\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.2780 - acc: 0.8819 - f1: 0.8773\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.2756 - acc: 0.8799 - f1: 0.8753\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.2749 - acc: 0.8803 - f1: 0.8752\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.2765 - acc: 0.8815 - f1: 0.8770\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.2690 - acc: 0.8868 - f1: 0.8820\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.2608 - acc: 0.8883 - f1: 0.8842\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.2594 - acc: 0.8910 - f1: 0.8866\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.2599 - acc: 0.8889 - f1: 0.8845\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.2510 - acc: 0.8935 - f1: 0.8893\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.2502 - acc: 0.8927 - f1: 0.8883\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.2482 - acc: 0.8953 - f1: 0.8911\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.2413 - acc: 0.8967 - f1: 0.8927\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.2413 - acc: 0.8962 - f1: 0.8922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28493408c18>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = preprocessing.scale(X)\n",
    "\n",
    "model.fit(X, Y, epochs=50, batch_size=1996, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the current model\n",
    "model.save(r'D:\\LICENTA\\models\\svm_{size1}x{size2}\\NeuralNet_{name}.h5'.format(size1=IMG_SIZE, size2=IMG_SIZE, name=MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\eduar\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\lib\\arraysetops.py:463: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test  (10000, 2048)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business</th>\n",
       "      <th>feature_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003sg</td>\n",
       "      <td>[0.11907065, 0.073270835, 0.10785412, 0.073216...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00er5</td>\n",
       "      <td>[0.13801534, 0.069412991, 0.10356507, 0.093447...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00kad</td>\n",
       "      <td>[0.11502581, 0.073984087, 0.12335605, 0.070464...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00mc6</td>\n",
       "      <td>[0.11302663, 0.069561109, 0.10974503, 0.097833...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00q7x</td>\n",
       "      <td>[0.080705076, 0.051065292, 0.079456739, 0.1045...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  business                                     feature_vector\n",
       "0    003sg  [0.11907065, 0.073270835, 0.10785412, 0.073216...\n",
       "1    00er5  [0.13801534, 0.069412991, 0.10356507, 0.093447...\n",
       "2    00kad  [0.11502581, 0.073984087, 0.12335605, 0.070464...\n",
       "3    00mc6  [0.11302663, 0.069561109, 0.10974503, 0.097833...\n",
       "4    00q7x  [0.080705076, 0.051065292, 0.079456739, 0.1045..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_FEATURES_PATH = DATA_DIR +  r'\\test_biz_{name}_features.csv'.format(name=MODEL_NAME)\n",
    "\n",
    "test_photo_to_biz = pd.read_csv('test_photo_to_biz.csv', index_col='photo_id')\n",
    "test_df = pd.read_csv(TEST_FEATURES_PATH)\n",
    "\n",
    "X_test = test_df['feature_vector'].values\n",
    "\n",
    "X_test = np.array([convert_feature_to_vector(x) for x in test_df['feature_vector']])\n",
    "\n",
    "print('X_test ', X_test.shape)\n",
    "test_df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 52.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "submission = pd.DataFrame(columns=['business_id','labels'])\n",
    "\n",
    "X_test = preprocessing.scale(X_test)\n",
    "\n",
    "y_predict = model.predict(X_test)\n",
    "y_predict = np.where(y_predict > 0.27, 1, 0)\n",
    "\n",
    "y_predict_label = mlb.inverse_transform(y_predict)\n",
    "\n",
    "for i in range(len(test_df)):\n",
    "    biz = test_df.loc[i]['business']\n",
    "    label = y_predict_label[i]\n",
    "    label = str(label)[1:-1].replace(',', ' ')\n",
    "    submission.loc[i] = [str(biz), label]\n",
    "\n",
    "with open('submission_NN.csv', 'w') as f:\n",
    "    submission.to_csv(f, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
