{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # liniear algebra\n",
    "import pandas as pd # csv I/O\n",
    "import os # file operations\n",
    "import h5py # handle data that doesn't fit in memory\n",
    "\n",
    "TRAIN_DIR = r'D:\\LICENTA\\train_photos'\n",
    "TEST_DIR = r'D:\\LICENTA\\test_photos'\n",
    "IMG_SIZE = 299\n",
    "\n",
    "DATA_DIR = r'D:\\LICENTA\\processed_data\\size_{size1}x{size2}'.format(size1=IMG_SIZE, size2=IMG_SIZE)\n",
    "\n",
    "train_labels = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# VGG16\n",
    "from keras.applications.vgg16 import VGG16 # predefined CNN Model\n",
    "from keras.preprocessing import image # get the array representation of the image\n",
    "from keras.applications.vgg16 import preprocess_input # get the array in a format compatible with the model\n",
    "\n",
    "# takes around 45 seconds\n",
    "model = VGG16(weights='imagenet', include_top=False, pooling='max')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# RESNET50\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "model = ResNet50(weights='imagenet', include_top=False, pooling='max')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# INCEPTION V3\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "model = InceptionV3(weights='imagenet', include_top=False, pooling='max')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# XCEPTION\n",
    "from keras.applications.xception import Xception\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.xception import preprocess_input\n",
    "\n",
    "model = Xception(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# INCEPTION_RESNET_V2\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "\n",
    "model = InceptionResNetV2(weights='imagenet', include_top=False, pooling='max')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'xception'\n",
    "FEATURE_VECTOR_SIZE = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(imgs_path, img_size):\n",
    "    \n",
    "    features = []\n",
    "    \n",
    "    for path in imgs_path:\n",
    "        img = image.load_img(path, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array = preprocess_input(img_array)\n",
    "        features.append(model.predict(img_array).reshape(FEATURE_VECTOR_SIZE,))\n",
    "    \n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE TRAIN DATA FILE\n",
    "\n",
    "with h5py.File(DATA_DIR + r'\\train_images_{name}_features_avg.h5'.format(name=MODEL_NAME), 'w') as f:\n",
    "    img_names = f.create_dataset('photo_id', (0,), maxshape=(None,), dtype='|S54')\n",
    "    feature = f.create_dataset('feature', (0, FEATURE_VECTOR_SIZE), maxshape=(None, FEATURE_VECTOR_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN PHOTOS\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "train_photos = pd.read_csv('train_photo_to_biz_ids.csv')\n",
    "train_images = [os.path.join(TRAIN_DIR, str(x) + '.jpg') for x in train_photos['photo_id']]\n",
    "\n",
    "num_train = len(train_images)\n",
    "print('Number of train images:', num_train, 'started at', str(datetime.now()))\n",
    "batch_size = 4000\n",
    "num_done = 0\n",
    "t = time.time()\n",
    "\n",
    "for i in range(0 , num_train, batch_size):\n",
    "    images = train_images[i:min(i + batch_size, num_train)]\n",
    "    features = extract_features(images, IMG_SIZE)\n",
    "    num_done = i + features.shape[0]\n",
    "    \n",
    "    with h5py.File(DATA_DIR + r'\\train_images_{name}_features_avg.h5'.format(name=MODEL_NAME), 'r+') as f:\n",
    "        f['photo_id'].resize((num_done,))\n",
    "        f['photo_id'][i:num_done] = np.array(images).astype('|S54')\n",
    "        f['feature'].resize((num_done, features.shape[1]))\n",
    "        f['feature'][i:num_done,:] = features\n",
    "    \n",
    "    if num_done % batch_size == 0 or num_done == num_train:\n",
    "        print('Train images proccesed:', num_done, 'time passed: ', '{0:.1f}'.format(time.time() - t), 'sec hour:', str(datetime.now()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\train_images_xception_features.h5\n",
      "feature (234842, 2048)\n",
      "photo_id (234842,)\n",
      "\n",
      "A photo: b'D:\\\\LICENTA\\\\train_photos\\\\204149.jpg'\n",
      "Its feature vector (first 10-dim):  [ 0.00866235  0.18051882  0.81814784  0.          0.32122934  0.01428686\n",
      "  0.          0.03974805  0.0128702   0.        ]  ...\n"
     ]
    }
   ],
   "source": [
    "# Check the file content\n",
    "\n",
    "with h5py.File(DATA_DIR + r'\\train_images_{name}_features_avg.h5'.format(name=MODEL_NAME),'r') as f:\n",
    "    print(r'\\train_images_{name}_features.h5'.format(name=MODEL_NAME))\n",
    "    for key in f.keys():\n",
    "        print(key, f[key].shape)\n",
    "\n",
    "    print(\"\\nA photo:\", f['photo_id'][0])\n",
    "    print(\"Its feature vector (first 10-dim): \", f['feature'][0][0:10], \" ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE TEST DATA FILE\n",
    "\n",
    "with h5py.File(DATA_DIR + r'\\test_images_{name}_features_avg.h5'.format(name=MODEL_NAME), 'w') as f:\n",
    "    img_names = f.create_dataset('photo_id', (0,), maxshape=(None,), dtype='|S54')\n",
    "    feature = f.create_dataset('feature', (0, FEATURE_VECTOR_SIZE), maxshape=(None, FEATURE_VECTOR_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST PHOTOS\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "test_photos = pd.read_csv('test_photo_to_biz.csv')\n",
    "test_images = [os.path.join(TEST_DIR, str(x) + '.jpg') for x in test_photos['photo_id'].unique()]\n",
    "\n",
    "num_test = len(test_images)\n",
    "print('Number of test images: ', num_test)\n",
    "batch_size = 4000\n",
    "t = time.time()\n",
    "\n",
    "for i in range(0, num_test, batch_size):\n",
    "    images = test_images[i:min(i + batch_size, num_test)]\n",
    "    features = extract_features(images, IMG_SIZE)\n",
    "    num_done = i + features.shape[0]\n",
    "    \n",
    "    with h5py.File(DATA_DIR + r'\\test_images_{name}_features_avg.h5'.format(name=MODEL_NAME), 'r+') as f:\n",
    "        f['photo_id'].resize((num_done,))\n",
    "        f['photo_id'][i:num_done] = np.array(images).astype('|S54')\n",
    "        f['feature'].resize((num_done, features.shape[1]))\n",
    "        f['feature'][i:num_done,:] = features\n",
    "    \n",
    "    if num_done % batch_size == 0 or num_done == num_test:\n",
    "        print('Test images proccesed:', num_done, 'time passed: ', '{0:.1f}'.format(time.time() - t), 'sec hour:', str(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature (237152, 2048)\n",
      "photo_id (237152,)\n",
      "\n",
      "A photo: b'D:\\\\LICENTA\\\\test_photos\\\\317818.jpg'\n",
      "feature vector: (first 10-dim) [ 0.00152443  0.          0.02481007  0.          0.          0.14680296\n",
      "  0.00110827  0.01223042  0.          0.0234869 ]  ...\n"
     ]
    }
   ],
   "source": [
    "# Check the file content\n",
    "\n",
    "with h5py.File(DATA_DIR + r'\\test_images_{name}_features_avg.h5'.format(name=MODEL_NAME),'r') as f:\n",
    "    for key in f.keys():\n",
    "        print(key, f[key].shape)\n",
    "\n",
    "    print(\"\\nA photo:\", f['photo_id'][0])\n",
    "    print(\"feature vector: (first 10-dim)\", f['feature'][0][0:10], \" ...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
