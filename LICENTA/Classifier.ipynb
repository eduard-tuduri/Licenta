{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # csv I/O\n",
    "\n",
    "IMG_SIZE = 299\n",
    "MODEL_NAME = 'xception'\n",
    "\n",
    "DATA_DIR= r'D:\\LICENTA\\processed_data\\size_{size1}x{size2}'.format(size1=IMG_SIZE, size2=IMG_SIZE)\n",
    "FEATURES_PATH = DATA_DIR +  r'\\train_biz_{name}_features.csv'.format(name=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_photos = pd.read_csv('train_photo_to_biz_ids.csv')\n",
    "train_photo_to_biz = pd.read_csv('train_photo_to_biz_ids.csv', index_col='photo_id')\n",
    "\n",
    "train_df = pd.read_csv(FEATURES_PATH)\n",
    "\n",
    "X = train_df['feature_vector'].values\n",
    "Y = train_df['label'].values\n",
    "\n",
    "def convert_label_to_array(str_label):\n",
    "    str_label = str_label[1:-1]\n",
    "    str_label = str_label.split(',')\n",
    "    return [int(x) for x in str_label if len(x) > 0]\n",
    "\n",
    "def convert_feature_to_vector(str_feature):\n",
    "    str_feature = str_feature[1:-1]\n",
    "    str_feature = str_feature.split(',')\n",
    "    return [float(x) for x in str_feature]\n",
    "\n",
    "Y = np.array([convert_label_to_array(y) for y in train_df['label']])\n",
    "X = np.array([convert_feature_to_vector(x) for x in train_df['feature_vector']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (1996, 2048)\n",
      "y_train:  (1996,)\n",
      "train_df:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business</th>\n",
       "      <th>label</th>\n",
       "      <th>feature_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 2, 3, 4, 5, 6, 7)</td>\n",
       "      <td>[0.98409426, 0.5011915, 0.80012208, 0.39773199...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>(0, 1, 6, 8)</td>\n",
       "      <td>[1.1223717, 0.39256608, 0.36077923, 1.2178262,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>(1, 2, 4, 5, 6, 7)</td>\n",
       "      <td>[1.0060079, 0.57109088, 0.84190941, 0.32770807...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1006</td>\n",
       "      <td>(1, 2, 4, 5, 6)</td>\n",
       "      <td>[1.1555356, 0.39558065, 0.63720721, 0.28982833...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1010</td>\n",
       "      <td>(0, 6, 8)</td>\n",
       "      <td>[0.98949295, 0.6631335, 0.60745454, 0.50947839...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   business                  label  \\\n",
       "0      1000  (1, 2, 3, 4, 5, 6, 7)   \n",
       "1      1001           (0, 1, 6, 8)   \n",
       "2       100     (1, 2, 4, 5, 6, 7)   \n",
       "3      1006        (1, 2, 4, 5, 6)   \n",
       "4      1010              (0, 6, 8)   \n",
       "\n",
       "                                      feature_vector  \n",
       "0  [0.98409426, 0.5011915, 0.80012208, 0.39773199...  \n",
       "1  [1.1223717, 0.39256608, 0.36077923, 1.2178262,...  \n",
       "2  [1.0060079, 0.57109088, 0.84190941, 0.32770807...  \n",
       "3  [1.1555356, 0.39558065, 0.63720721, 0.28982833...  \n",
       "4  [0.98949295, 0.6631335, 0.60745454, 0.50947839...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"X_train: \", X.shape)\n",
    "print(\"y_train: \", Y.shape)\n",
    "print(\"train_df:\")\n",
    "train_df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (1596, 2048)\n",
      "X_test:  (400, 2048)\n",
      "y_train:  (1596, 9)\n",
      "y_test:  (400, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\eduar\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "c:\\users\\eduar\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y = mlb.fit_transform(Y)\n",
    "\n",
    "random_state = np.random.RandomState(0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "print('X_train: ',X_train.shape)\n",
    "print('X_test: ', X_test.shape)\n",
    "print('y_train: ', y_train.shape)\n",
    "print('y_test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 34.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf = OneVsRestClassifier(svm.SVC(kernel='rbf'), n_jobs=-1)\n",
    "X_train = preprocessing.scale(X_train)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "X_test = preprocessing.scale(X_test)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "# parameters = {\n",
    "#     \"estimator__C\": [1,2,4,8],\n",
    "#     \"estimator__kernel\": [\"poly\",\"rbf\"],\n",
    "#     \"estimator__degree\":[1, 2, 3, 4],\n",
    "# }\n",
    "\n",
    "# model_tunning = GridSearchCV(clf, param_grid=parameters,\n",
    "#                              scoring='f1_micro', n_jobs=-1)\n",
    "# model_tunning.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3175"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.84980820301\n",
      "F1 Individual Score:  [ 0.77777778  0.81538462  0.90537084  0.70076726  0.78640777  0.89711934\n",
      "  0.93333333  0.76651982  0.91803279]\n"
     ]
    }
   ],
   "source": [
    "# print(model_tunning.best_score_)\n",
    "# print(model_tunning.best_params_)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='micro'))\n",
    "print('F1 Individual Score: ', f1_score(y_test, y_pred, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(r'D:\\LICENTA\\models\\svm_{size1}x{size2}\\svm_{name}.pkl'.format(size1=IMG_SIZE, size2=IMG_SIZE, name=MODEL_NAME), 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0 0 1 1 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\eduar\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:164: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "c:\\users\\eduar\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:181: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "# testing with outside photos\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import os\n",
    "\n",
    "# takes around 45 seconds\n",
    "model = VGG16(weights='imagenet', include_top=False, pooling='max')\n",
    "\n",
    "TEST_DIR = r'D:\\Retro Test Photos'\n",
    "        \n",
    "features = []\n",
    "\n",
    "for path in list(os.listdir(TEST_DIR)):\n",
    "    img = image.load_img(os.path.join(TEST_DIR, path), target_size=(IMG_SIZE, IMG_SIZE))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    features.append(model.predict(img_array).reshape(512,))\n",
    "    \n",
    "test = np.mean(np.array(features), axis=0)\n",
    "\n",
    "test = test.reshape(512,)\n",
    "test = preprocessing.scale(test)\n",
    "test = test.reshape(1, -1)\n",
    "prediction = clf.predict(test)\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
