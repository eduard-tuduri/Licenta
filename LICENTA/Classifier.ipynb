{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\eduar\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "c:\\users\\eduar\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm, preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "IMG_SIZE = 50\n",
    "FEATURES_PATH = r'D:\\LICENTA\\processed_data\\size_{size1}x{size2}\\biz_to_features.npy'.format(size1=IMG_SIZE, size2=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(FEATURES_PATH)\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    train_data[:,1][i] = train_data[:,1][i].reshape(512,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_ids = train_data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.dropna(axis=0, inplace=True)\n",
    "\n",
    "train_ids = df['business_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels_to_array():\n",
    "    labels = []\n",
    "    \n",
    "    for str_label in df['labels'].values:\n",
    "        str_label = str_label.split(' ')\n",
    "        str_labels = [int(x) for x in str_label if len(x)>0]\n",
    "                \n",
    "        labels.append(str_labels)\n",
    "    return np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1996,)\n"
     ]
    }
   ],
   "source": [
    "new_train_data = train_data[:,1]\n",
    "\n",
    "print(new_train_data.shape)\n",
    "\n",
    "X = []\n",
    "\n",
    "for i in range(len(new_train_data)):\n",
    "    X.append(new_train_data[i])\n",
    "    \n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = convert_labels_to_array()\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  (1996, 512)\n",
      "y:  (1996, 9)\n"
     ]
    }
   ],
   "source": [
    "print('X: ', X.shape)\n",
    "print('y: ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (1596, 512)\n",
      "X_test:  (400, 512)\n",
      "y_train:  (1596, 9)\n",
      "y_test:  (400, 9)\n"
     ]
    }
   ],
   "source": [
    "random_state = np.random.RandomState(0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "print('X_train: ',X_train.shape)\n",
    "print('X_test: ', X_test.shape)\n",
    "print('y_train: ', y_train.shape)\n",
    "print('y_test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\eduar\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:164: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "c:\\users\\eduar\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:181: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf = OneVsRestClassifier(svm.SVC(kernel='rbf'), n_jobs=-1)\n",
    "X_train = preprocessing.scale(X_train)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "X_test = preprocessing.scale(X_test)\n",
    "y_pred = clf.predict(X_test)\n",
    "# parameters = {\n",
    "#     \"estimator__C\": [1,2,4,8],\n",
    "#     \"estimator__kernel\": [\"poly\",\"rbf\"],\n",
    "#     \"estimator__degree\":[1, 2, 3, 4],\n",
    "# }\n",
    "\n",
    "# model_tunning = GridSearchCV(clf, param_grid=parameters,\n",
    "#                              scoring='f1_micro', n_jobs=-1)\n",
    "# model_tunning.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.632669322709\n",
      "F1 Individual Score:  [ 0.          0.47878788  0.65084746  0.60721063  0.          0.76923077\n",
      "  0.8005997   0.08333333  0.7496063 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\eduar\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# print(model_tunning.best_score_)\n",
    "# print(model_tunning.best_params_)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='micro'))\n",
    "print('F1 Individual Score: ', f1_score(y_test, y_pred, average=None))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
